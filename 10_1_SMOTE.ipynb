{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "10e1abf77ddef6b5a0d462bd0c1af8a6d69cacf984b7ff54f171d3af9bd75ca1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  pd.read_csv(r\"C:\\Users\\Duong Nguyen\\Desktop\\final_project\\home-credit-default-risk\\results\\1_9_combined_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns = list(map(lambda x: str(x).replace(\" \", \"_\").replace(\"-\", \"_\").replace(\"_/_\", \"_\").upper(), dataset.columns))\n",
    "import re\n",
    "dataset = dataset.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10        84\n",
       "11     64238\n",
       "12    238024\n",
       "13     42160\n",
       "14       104\n",
       "Name: AMT_INCOME_TOTAL_GROUP, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "#create stratifying field\n",
    "strat_field = 'AMT_INCOME_TOTAL'\n",
    "\n",
    "strat_column = strat_field + \"_GROUP\"\n",
    "\n",
    "dataset[strat_column] = dataset[strat_field].apply(lambda x:int(  round(x)))\n",
    "dataset[strat_column] = dataset[strat_column].apply(lambda x: 14 if x==15 else x)\n",
    "dataset[strat_column].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset[dataset.TARGET.isna() == False]\n",
    "test_df = dataset[dataset.TARGET.isna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop([\"TARGET\", \"SK_ID_CURR\",strat_field], axis = 1)\n",
    "X_test = train_df.drop([\"TARGET\", \"SK_ID_CURR\",strat_field], axis = 1)\n",
    "y_train = train_df.TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dropna(axis='columns',inplace=True)\n",
    "X_test.dropna(axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X training size: (266369, 38) and y training size (266369,):\nX validation size: (29597, 38) and y testing size (29597,):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split into train/test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=54,stratify=y_train)\n",
    "print(\"X training size: {} and y training size {}:\".format(X_train.shape,y_train.shape))\n",
    "print(\"X validation size: {} and y testing size {}:\".format(X_val.shape,y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = X_train.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'NAME_INCOME_TYPE',\n",
       "       'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 AMT_CREDIT\n1 AMT_ANNUITY\n2 REGION_POPULATION_RELATIVE\n3 DAYS_REGISTRATION\n4 EXT_SOURCE_2\n5 DEF_60_CNT_SOCIAL_CIRCLE\n6 DAYS_LAST_PHONE_CHANGE\n7 EXT_SOURCE_1\n8 EXT_SOURCE_3\n9 CREDIT_INCOME_PERCENT\n10 ANNUITY_INCOME_PERCENT\n11 CREDIT_TERM\n12 DAYS_EMPLOYED_PERCENT\n13 RETIRED\n14 DAYS_BIRTH\n15 DAYS_EMPLOYED\n16 DAYS_ID_PUBLISH\n17 FLAG_EMP_PHONE\n18 FLAG_WORK_PHONE\n19 FLAG_PHONE\n20 REGION_RATING_CLIENT\n21 REGION_RATING_CLIENT_W_CITY\n22 HOUR_APPR_PROCESS_START\n23 REG_REGION_NOT_WORK_REGION\n24 REG_CITY_NOT_LIVE_CITY\n25 REG_CITY_NOT_WORK_CITY\n26 LIVE_CITY_NOT_WORK_CITY\n27 FLAG_DOCUMENT_3\n28 FLAG_DOCUMENT_6\n29 FLAG_DOCUMENT_8\n30 NAME_CONTRACT_TYPE\n31 CODE_GENDER\n32 FLAG_OWN_CAR\n33 NAME_INCOME_TYPE\n34 NAME_EDUCATION_TYPE\n35 NAME_FAMILY_STATUS\n36 NAME_HOUSING_TYPE\n37 AMT_INCOME_TOTAL_GROUP\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(X_train.columns):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the SMOTE-NC\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "#Create the oversampler. \n",
    "smotenc = SMOTENC([30,31,32,33,34,35,36,37],random_state = 101)\n",
    "X_oversample, y_oversample = smotenc.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_oversample\n",
    "y_train = y_oversample.astype('int')\n",
    "y_val = y_val.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(489566, 38)\n(29597, 38)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train,X_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_col = train_df.select_dtypes(['float']).columns\n",
    "float_col = float_col.values.tolist() +['DAYS_BIRTH','DAYS_EMPLOYED','DAYS_ID_PUBLISH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in float_col:\n",
    "    #first normalize training dataset\n",
    "    #get ids of training datasets\n",
    "    ids_train = train_df[feature].index.values\n",
    "    \n",
    "    #perform standarization\n",
    "    vals_train = train_df[feature].values.reshape(-1, 1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(vals_train)\n",
    "    # scaler = StandardScaler().fit(vals_train)\n",
    "    x_train = scaler.transform(vals_train)\n",
    "\n",
    "    #update training values\n",
    "    X_update_train = pd.DataFrame(x_train.flatten(), columns=[feature], index=ids_train)\n",
    "    train_df.update(X_update_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_col = train_df.select_dtypes(['integer']).columns\n",
    "int_table = train_df[int_col]\n",
    "#integer one-hot-encoding\n",
    "train_df = pd.get_dummies(train_df, columns = int_table.columns, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features = train_df.select_dtypes(['object']).columns\n",
    "# One hot encode all the string fields\n",
    "drop_features =[]\n",
    "one_hot_features = []\n",
    "for f in other_features:\n",
    "    #get unique values from feature\n",
    "    idx = train_df.groupby(f).size().index\n",
    "    mapper = {f:i for i,f in enumerate(idx)}\n",
    "    \n",
    "    #lets create new map fields\n",
    "    one_hot = f + \"_MAP\"\n",
    "    train_df[one_hot] = train_df[f].map(mapper)\n",
    "\n",
    "    drop_features.append(f)\n",
    "    one_hot_features.append(one_hot)\n",
    "\n",
    "#lets drop original features \n",
    "train_df.drop(drop_features,axis=1,inplace=True)\n",
    "\n",
    "#one-hot-encoding\n",
    "train_df = pd.get_dummies(train_df, columns=one_hot_features, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.iloc[:489566,:]\n",
    "X_val =train_df.iloc[489566:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml algorithms\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "#nerual networks api\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[50]\ttraining's auc: 0.923974\ttraining's binary_logloss: 0.416911\tvalid_1's auc: 0.63763\tvalid_1's binary_logloss: 0.458442\n",
      "[100]\ttraining's auc: 0.950088\ttraining's binary_logloss: 0.317739\tvalid_1's auc: 0.649792\tvalid_1's binary_logloss: 0.380289\n",
      "[150]\ttraining's auc: 0.961181\ttraining's binary_logloss: 0.261657\tvalid_1's auc: 0.660677\tvalid_1's binary_logloss: 0.338878\n",
      "[200]\ttraining's auc: 0.965437\ttraining's binary_logloss: 0.233106\tvalid_1's auc: 0.669712\tvalid_1's binary_logloss: 0.318943\n",
      "[250]\ttraining's auc: 0.967507\ttraining's binary_logloss: 0.217604\tvalid_1's auc: 0.674996\tvalid_1's binary_logloss: 0.309046\n",
      "[300]\ttraining's auc: 0.969109\ttraining's binary_logloss: 0.205737\tvalid_1's auc: 0.679193\tvalid_1's binary_logloss: 0.301582\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_model = LGBMClassifier(learning_rate= 0.04,\n",
    "                             max_depth= 20,\n",
    "                             n_estimators= 300,\n",
    "                             num_leaves= 25,\n",
    "                             random_state = 54)\n",
    "\n",
    "final_model.fit(X_train, y_train ,verbose=50, \n",
    "                eval_set=[(X_train, y_train),(X_val, y_val)], \n",
    "                eval_metric= 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[26257,   942],\n",
       "       [ 2169,   229]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = final_model.predict(X_val)\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-86b63c2d0e14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLGBM_conf\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Not Default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Default'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLGBM_conf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"LGBM\\n Confusion Matrix\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOranges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "LGBM_conf= confusion_matrix(y_test.values, y_pred)\n",
    "labels = ['Not Default', 'Default']\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plot_confusion_matrix(LGBM_conf, labels, title=\"LGBM\\n Confusion Matrix\", cmap=plt.cm.Oranges, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}